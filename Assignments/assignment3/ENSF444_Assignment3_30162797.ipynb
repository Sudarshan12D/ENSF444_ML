{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "CNDKREiQRJJX",
      "metadata": {
        "id": "CNDKREiQRJJX"
      },
      "source": [
        "<font size=\"+3\"><b>Assignment 3: Non-Linear Models and Validation Metrics</b></font>\n",
        "\n",
        "***\n",
        "* **Full Name** = Sudarshan Naicker\n",
        "* **UCID** = 30162797\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce31b39a",
      "metadata": {
        "id": "ce31b39a"
      },
      "source": [
        "<font color='Blue'>\n",
        "In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment.\n",
        "</font>\n",
        "\n",
        "|                **Question**                | **Point** |\n",
        "|:------------------------------------------:|:---------:|\n",
        "|           **Part 1: Regression**           |  **14.5** |\n",
        "|          Step 0: Import Libraries          |           |\n",
        "|             Step 1: Data Input             |    0.5    |\n",
        "|           Step 2: Data Processing          |     0     |\n",
        "| Step 3: Implement   Machine Learning Model |    0.5    |\n",
        "|           Step 4: Validate Model           |    0.5    |\n",
        "|         Step 5: Visualize   Results        |     3     |\n",
        "|                  Questions                 |     6     |\n",
        "|             Process Description            |     4     |\n",
        "|         **Part 2: Classification**         |  **17.5** |\n",
        "|             Step 1: Data Input             |     2     |\n",
        "|           Step 2: Data Processing          |    1.5    |\n",
        "| Step 3: Implement   Machine Learning Model |           |\n",
        "|            Step 4: Validate Mode           |           |\n",
        "|         Step 5: Visualize   Results        |     4     |\n",
        "|                  Questions                 |     6     |\n",
        "|             Process Description            |     4     |\n",
        "|   **Part 3: Observations/Interpretation**  |   **3**   |\n",
        "|           **Part 4: Reflection**           |   **2**   |\n",
        "|                  **Total**                 |   **37**  |\n",
        "|                                            |           |\n",
        "|                  **Bonus**                 |           |\n",
        "|         **Part 5: Bonus Question**         |   **3**   |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf275ca7",
      "metadata": {
        "id": "cf275ca7"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2b67a661",
      "metadata": {
        "id": "2b67a661"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ee2d2c3",
      "metadata": {
        "id": "5ee2d2c3"
      },
      "source": [
        "# **Part 1: Regression (14.5 marks)**\n",
        "\n",
        "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8219f163",
      "metadata": {
        "id": "8219f163"
      },
      "source": [
        "## **Step 1:** Data Input (0.5 marks)\n",
        "\n",
        "The data used for this task can be downloaded using the yellowbrick library:\n",
        "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
        "\n",
        "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2af8bd32",
      "metadata": {
        "id": "2af8bd32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of X: 8240\n",
            "Type of X: <class 'pandas.core.frame.DataFrame'>\n",
            "Size of y: 1030\n",
            "Type of y: <class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Import concrete dataset from yellowbrick library\n",
        "from yellowbrick.datasets import load_concrete\n",
        "\n",
        "\n",
        "X, y = load_concrete()\n",
        "print('Size of X:', X.size)\n",
        "print('Type of X:', type(X))\n",
        "print('Size of y:', y.size)\n",
        "print('Type of y:', type(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42fea4cc",
      "metadata": {
        "id": "42fea4cc"
      },
      "source": [
        "## **Step 2:** Data Processing (0 marks)\n",
        "\n",
        "Data processing was completed in the previous assignment. No need to repeat here.\n",
        "\n",
        "<font color='red'>\n",
        "This is just for your information and no action is required from you for this step.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a245d00",
      "metadata": {
        "id": "2a245d00"
      },
      "source": [
        "## **Step 3:** Implement Machine Learning Model (0.5 marks)\n",
        "\n",
        "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
        "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
        "3. Implement each machine learning model with `X` and `y`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f994e31",
      "metadata": {
        "id": "3f994e31"
      },
      "source": [
        "## **Step 4:** Validate Model (0.5 marks)\n",
        "\n",
        "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fc3f7a8",
      "metadata": {
        "id": "5fc3f7a8"
      },
      "source": [
        "## **Step 5:** Visualize Results (3 marks)\n",
        "\n",
        "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
        "2. Add the accuracy results to the `results` DataFrame\n",
        "3. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fdc93a78",
      "metadata": {
        "id": "fdc93a78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Training accuracy Validation accuracy\n",
            "DT         47.918561          163.087775\n",
            "RF         32.055432          156.404972\n",
            "GB           3.73927           99.360259\n"
          ]
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
        "# Note: for any random state parameters, you can use random_state = 0\n",
        "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.model_selection import cross_validate\n",
        "import pandas as pd\n",
        "\n",
        "models = {\n",
        "    'DT': DecisionTreeRegressor(max_depth=5, random_state=0),\n",
        "    'RF': RandomForestRegressor(max_depth=5, random_state=0),\n",
        "    'GB': GradientBoostingRegressor(max_depth=5, random_state=0)\n",
        "}\n",
        "\n",
        "results = pd.DataFrame(index=['DT', 'RF', 'GB'], columns=['Training accuracy', 'Validation accuracy'])\n",
        "\n",
        "for name, model in models.items():\n",
        "    cv_results = cross_validate(model, X, y, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
        "    results.loc[name, 'Training accuracy'] = -cv_results['train_score'].mean()\n",
        "    results.loc[name, 'Validation accuracy'] = -cv_results['test_score'].mean()\n",
        "\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31715a9d",
      "metadata": {
        "id": "31715a9d"
      },
      "source": [
        "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`.\n",
        "\n",
        "<font color='red'>\n",
        "Due to the similarity of this to the main part of step 5, this part is 0.5 and the main part of step 5 is 2.5 of the total 3 points for this step.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "83539f47",
      "metadata": {
        "id": "83539f47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Training accuracy Validation accuracy\n",
            "DT          0.822887             0.17621\n",
            "RF          0.881221            0.173748\n",
            "GB          0.986436            0.473701\n"
          ]
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "# This would be similar to the main step, the main difference is the scoring.\n",
        "results2 = pd.DataFrame(index=['DT', 'RF', 'GB'], columns=['Training accuracy', 'Validation accuracy'])\n",
        "\n",
        "for name, model in models.items():\n",
        "    cv_results2 = cross_validate(model, X, y, cv=5, scoring='r2', return_train_score=True)\n",
        "    results.loc[name, 'Training accuracy'] = cv_results2['train_score'].mean()\n",
        "    results.loc[name, 'Validation accuracy'] = cv_results2['test_score'].mean()\n",
        "\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5257a98",
      "metadata": {
        "id": "a5257a98"
      },
      "source": [
        "## Questions (6 marks)\n",
        "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
        "1. Out of the models you tested, which model would you select for this dataset and why?\n",
        "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2PRnpiFjVDzv",
      "metadata": {
        "id": "2PRnpiFjVDzv"
      },
      "source": [
        "<font color='Green'><b>YOUR ANSWERS HERE</b></font>\n",
        "\n",
        "1) Linear Model: has an MSE of 95.635 (higher the better) and a R2 score of 0.636 on the validation set.\n",
        "   tree-models: none of the 3 models have a better R2 score as they are all much lower than 0.6. the higher NSME (close to 0) means there are fewer errors. most of the NSME values are far away from 0.\n",
        "\n",
        "   Hence Linear model is performing better on the validation set than the other 3 models. \n",
        " \n",
        "\n",
        "2) Negative Mean Squared Error (NMSE): Lower NMSE values (closer to zero) are better since they indicate a smaller error. The Gradient     \n",
        "   Booster model has the lowest NMSE for validation accuracy compared to the Decision Tree and Random Forest models, which means that it is making fewer mistakes on the validation set.\n",
        "\n",
        "   R² Score: Higher R² values (closer to 1) indicate a better fit. The Gradient Booster has the highest R² score for the validation accuracy, hence it is able to capture the data points better than  the other 2 models.\n",
        "\n",
        "3) - We could increase the number of features in the dataset this would give the model more chances to learn and correct its mistakes.\n",
        "   - We could change the Parameters like having more depth of trees or more number of trees."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37b238f4",
      "metadata": {
        "id": "37b238f4"
      },
      "source": [
        "## Process Description (4 marks)\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93097bfe",
      "metadata": {
        "id": "93097bfe"
      },
      "source": [
        "<font color='Green'><b>DESCRIBE YOUR PROCESS HERE</b></font>\n",
        "\n",
        "1) I had to review through the Lab_4_Decission_trees_and_svc.ipynb file to understand about  decision trees and random forest models.\n",
        "2) I completed them from step 1 to 5\n",
        "3) yes, I used AI to help me with creating the for loop, inorder to put all the models in one list and use for loop to calculate their scores rather than training each model one by one. Using AI helped me to understand an easier, more readable and shorter way to write python codes.\n",
        "4) No this part was very straightforward. easy to understand the question and go with the flow."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7c6de86",
      "metadata": {
        "id": "f7c6de86"
      },
      "source": [
        "# **Part 2: Classification (17.5 marks)**\n",
        "\n",
        "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f9d33a8",
      "metadata": {
        "id": "5f9d33a8"
      },
      "source": [
        "## **Step 1:** Data Input (2 marks)\n",
        "\n",
        "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
        "\n",
        "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset\n",
        "\n",
        "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
        "\n",
        "Print the size and type of `X` and `y`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "33583c67",
      "metadata": {
        "id": "33583c67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature matrix X has size: 2314 and types: \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "\n",
            "Target vector y has size: 178 and type: \n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Import wine dataset\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "import pandas as pd \n",
        "  \n",
        "# fetch dataset \n",
        "wine = fetch_ucirepo(id=109) \n",
        "  \n",
        "# data (as pandas dataframes) \n",
        "X = wine.data.features \n",
        "y = wine.data.targets \n",
        "\n",
        "print(f'Feature matrix X has size: {X.size} and types: \\n{type(X)}')\n",
        "print(f'\\nTarget vector y has size: {y.size} and type: \\n{type(y)}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156db208",
      "metadata": {
        "id": "156db208"
      },
      "source": [
        "## **Step 2:** Data Processing (1.5 marks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a28af110",
      "metadata": {
        "id": "a28af110"
      },
      "source": [
        "Print the first five rows of the dataset to inspect:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ea266921",
      "metadata": {
        "id": "ea266921"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Malicacid</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Alcalinity_of_ash</th>\n",
              "      <th>Magnesium</th>\n",
              "      <th>Total_phenols</th>\n",
              "      <th>Flavanoids</th>\n",
              "      <th>Nonflavanoid_phenols</th>\n",
              "      <th>Proanthocyanins</th>\n",
              "      <th>Color_intensity</th>\n",
              "      <th>Hue</th>\n",
              "      <th>0D280_0D315_of_diluted_wines</th>\n",
              "      <th>Proline</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
              "0    14.23       1.71  2.43               15.6        127           2.80   \n",
              "1    13.20       1.78  2.14               11.2        100           2.65   \n",
              "2    13.16       2.36  2.67               18.6        101           2.80   \n",
              "3    14.37       1.95  2.50               16.8        113           3.85   \n",
              "4    13.24       2.59  2.87               21.0        118           2.80   \n",
              "\n",
              "   Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
              "0        3.06                  0.28             2.29             5.64  1.04   \n",
              "1        2.76                  0.26             1.28             4.38  1.05   \n",
              "2        3.24                  0.30             2.81             5.68  1.03   \n",
              "3        3.49                  0.24             2.18             7.80  0.86   \n",
              "4        2.69                  0.39             1.82             4.32  1.04   \n",
              "\n",
              "   0D280_0D315_of_diluted_wines  Proline  Target  \n",
              "0                          3.92     1065       1  \n",
              "1                          3.40     1050       1  \n",
              "2                          3.17     1185       1  \n",
              "3                          3.45     1480       1  \n",
              "4                          2.93      735       1  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "df = pd.DataFrame(X, columns=wine.data.feature_names)\n",
        "df['Target'] = y  # Add target column\n",
        "\n",
        "# Display the DataFrame\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "834fc8fe",
      "metadata": {
        "id": "834fc8fe"
      },
      "source": [
        "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "97c6e9dc",
      "metadata": {
        "id": "97c6e9dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values in X:\n",
            " Alcohol                         0\n",
            "Malicacid                       0\n",
            "Ash                             0\n",
            "Alcalinity_of_ash               0\n",
            "Magnesium                       0\n",
            "Total_phenols                   0\n",
            "Flavanoids                      0\n",
            "Nonflavanoid_phenols            0\n",
            "Proanthocyanins                 0\n",
            "Color_intensity                 0\n",
            "Hue                             0\n",
            "0D280_0D315_of_diluted_wines    0\n",
            "Proline                         0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in y:  class    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "\n",
        "missing_values_X = X.isnull().sum()\n",
        "missing_values_y = y.isnull().sum()\n",
        "print(\"Missing values in X:\\n\", missing_values_X)\n",
        "print(\"\\nMissing values in y: \", missing_values_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "070956af",
      "metadata": {
        "id": "070956af"
      },
      "source": [
        "How many samples do we have of each type of wine?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b37a6fd9",
      "metadata": {
        "id": "b37a6fd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target\n",
            "2    71\n",
            "1    59\n",
            "3    48\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "sample_counts = df['Target'].value_counts()\n",
        "print(sample_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70e6c46f",
      "metadata": {
        "id": "70e6c46f"
      },
      "source": [
        "## **Step 3:** Implement Machine Learning Model\n",
        "\n",
        "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
        "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
        "3. Implement the machine learning model with `X` and `y`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0870b0d2",
      "metadata": {
        "id": "0870b0d2"
      },
      "source": [
        "## **Step 4:** Validate Model\n",
        "\n",
        "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb0bbd83",
      "metadata": {
        "id": "bb0bbd83"
      },
      "source": [
        "## **Step 5:** Visualize Results (4 marks)\n",
        "\n",
        "<font color='red'>\n",
        "There is no individual mark for Steps 3 and 4 and those grades are included within the four points.\n",
        "\n",
        "</font>\n",
        "\n",
        "### **Step 5.1:** Compare Models (2 out of total 4 marks)\n",
        "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
        "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
        "3. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "be4b5c0a",
      "metadata": {
        "id": "be4b5c0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              Training accuracy Validation accuracy\n",
            "SVC                    0.703743            0.663492\n",
            "Decision Tree          0.974756            0.893175\n"
          ]
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
        "# Note: for any random state parameters, you can use random_state = 0\n",
        "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "import pandas as pd\n",
        "\n",
        "y = y.values.ravel() # to change the shape of y to (n_samples, )\n",
        "\n",
        "models = {\n",
        "    'SVC': SVC(random_state=0),\n",
        "    'Decision Tree': DecisionTreeClassifier(max_depth=3, random_state=0)\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(index=['SVC', 'Decision Tree'], columns=['Training accuracy', 'Validation accuracy'])\n",
        "\n",
        "# Perform cross-validation for each model\n",
        "for name, model in models.items():\n",
        "    cv_results3 = cross_validate(model, X, y, cv=5, scoring='accuracy', return_train_score=True)\n",
        "\n",
        "    results_df.loc[name, 'Training accuracy'] = cv_results3['train_score'].mean()\n",
        "    results_df.loc[name, 'Validation accuracy'] = cv_results3['test_score'].mean()\n",
        "\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2e17878",
      "metadata": {
        "id": "f2e17878"
      },
      "source": [
        "### **Step 5.2:** Visualize Classification Errors  (2 out of total 4 marks)\n",
        "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "44b091a4",
      "metadata": {
        "id": "44b091a4"
      },
      "outputs": [],
      "source": [
        "# TO DO: Implement best model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "best_model = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
        "\n",
        "\n",
        "best_model.fit(X, y)\n",
        "y_pred = best_model.predict(X)\n",
        "confusion = confusion_matrix(y, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "09d21b59",
      "metadata": {
        "id": "09d21b59"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# TO DO: Print confusion matrix using a heatmap\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues', cbar=True, annot_kws={\"size\": 12})\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5ef95947",
      "metadata": {
        "id": "5ef95947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.97      0.98        59\n",
            "           2       0.96      0.99      0.97        71\n",
            "           3       0.98      0.98      0.98        48\n",
            "\n",
            "    accuracy                           0.98       178\n",
            "   macro avg       0.98      0.98      0.98       178\n",
            "weighted avg       0.98      0.98      0.98       178\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Print classification report\n",
        "print(classification_report(y, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf319621",
      "metadata": {
        "id": "bf319621"
      },
      "source": [
        "## Questions (6 marks)\n",
        "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
        "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
        "1. How many samples were incorrectly classified in step 5.2?\n",
        "1. In this case, is maximizing precision or recall more important? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1FQstcwnXXng",
      "metadata": {
        "id": "1FQstcwnXXng"
      },
      "source": [
        "\n",
        "<font color='Green'><b>YOUR ANSWERS HERE</b></font>\n",
        "\n",
        "1) As seen in the result SVC has 0.70 % Accuracy for Training set and 0.66 % Accuracy for validation set which is lower compared to the Decision tree model which has 0.97% and 0.89% Accuracy for training and validation set respectively. hence the accuracy scores improved by changing the model from SVC to Descission tree.\n",
        "\n",
        "2)  The SVC might not be well-tuned for the dataset. since they have multiple hyperparameters like C, kernel, and gamma that can affect the performance\n",
        "\n",
        "3) for class 1 with 59 samples 57 are correctly labeled and the remaining <b>2</b> are labelled as class 2.\n",
        "\n",
        "4) Precision means having all wines classified correctly. Recall means having a certain category of wines to be classified correctly. Here recall score maters more because we would typically wants expensive wines to NOT be misclassified."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "664ff8ae",
      "metadata": {
        "id": "664ff8ae"
      },
      "source": [
        "## Process Description (4 marks)\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0e837da",
      "metadata": {
        "id": "d0e837da"
      },
      "source": [
        "<font color='Green'><b>DESCRIBE YOUR PROCESS HERE</b></font>\n",
        "\n",
        "1) I had to review through the Lab_4_Decission_trees_and_svc.ipynb file to understand about  decision trees and random forest models.\n",
        "2) I completed them from step 1 to 5\n",
        "3) yes, I used AI to help me the confusion matrix as the question was confusing and it helped me to understand how to calculate the classification report.\n",
        "4) Yes, i had problems with the confusion matrix as i was not able to find similar examples in the labs so i took help of chatgpt to leanr how to solve the confusion matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cd7358d",
      "metadata": {
        "id": "4cd7358d"
      },
      "source": [
        "# **Part 3: Observations/Interpretation (3 marks)**\n",
        "\n",
        "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "F3ifv218XL62",
      "metadata": {
        "id": "F3ifv218XL62"
      },
      "source": [
        "<font color='Green'><b>\n",
        "ADD YOUR FINDINGS HERE\n",
        "</b></font>\n",
        "\n",
        "Part 1: I found that Gradient booster has performed better in both NMSE and R2 score than the decision tree or Random forest models.\n",
        "<br>\n",
        "Part 2: \n",
        "- As seen in the classification report class 1 had highest precision of 1 this means that every time it predicted class 1, it was       \n",
        "  correct (no false positives). The recall is 0.97, which means it correctly identified 97% of all actual class 1 instances (there were some false negatives).\n",
        "        \n",
        "- For class 3, both precision and recall are 0.98, which means it has a balanced performance in terms of both false positives and    \n",
        "  false negatives for class 3."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd97b6ac",
      "metadata": {
        "id": "cd97b6ac"
      },
      "source": [
        "## **Part 4:** Reflection (2 marks)\n",
        "Include a sentence or two about:\n",
        "- what you liked or disliked,\n",
        "- found interesting, confusing, challangeing, motivating\n",
        "while working on this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tDFYc89YXQGJ",
      "metadata": {
        "id": "tDFYc89YXQGJ"
      },
      "source": [
        "<font color='Green'><b>\n",
        "ADD YOUR THOUGHTS HERE\n",
        "</b></font>\n",
        "\n",
        "\n",
        "- I liked Part 1 it was much easier to understand the questions were straightforward.\n",
        "- Part 2 was challenging. first obstacle was importing the model, there were different ways to import it from https://archive.ics.uci.edu/dataset/109/wine. like downloading the csv file etc. after reading through the document i found that we can perform pip install ucimlrepo ad then import the dataset to our local system which was much easier and simpler. Then the confusion matrix was confusing as the question just asked print the confusion matrix, I tried searching the labs but couldnt find any examples, Hence I aksed my classmates and AI to learn how to work on this and came with a solution to split the dataset, train the model and and calculate the confusion matrix. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa21e53b",
      "metadata": {
        "id": "fa21e53b"
      },
      "source": [
        "## **Part 5:** Bonus Question (3 marks)\n",
        "\n",
        "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
        "\n",
        "Is `LinearSVC` a good fit for this dataset? Why or why not?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "30fea72e",
      "metadata": {
        "id": "30fea72e"
      },
      "outputs": [],
      "source": [
        "# TO DO: ADD YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aabc68a4",
      "metadata": {
        "id": "aabc68a4"
      },
      "source": [
        "*ANSWER HERE*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "241c3b12",
      "metadata": {
        "id": "241c3b12"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
